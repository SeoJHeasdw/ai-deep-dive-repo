"""
[Chapter 3] 심화 이론 - 확장성과 최적화
- 실습 6: ANN 인덱스 알고리즘 이해하기 (HNSW, IVF, PQ)
- 실습 7: 대용량 데이터 처리 전략

학습 목표:
• Vector DB가 빠른 이유 (ANN 알고리즘 원리)
• HNSW, IVF, PQ 등 주요 인덱스 알고리즘 비교
• 100만 건 이상 벡터 처리 시 고려사항
• 샤딩, 캐싱, 배치 처리 전략

특징:
이 챕터는 이론 중심이므로 API 호출 없이 학습 가능합니다.

실행:
  python chapter3_advanced_topics.py
"""

import sys
from pathlib import Path
from dotenv import load_dotenv

# 프로젝트 루트의 .env 파일 로드
project_root = Path(__file__).parent.parent
load_dotenv(dotenv_path=project_root / '.env')

# 공통 유틸리티 import
sys.path.insert(0, str(project_root))
from utils import (
    print_section_header,
    print_subsection,
    print_key_points,
)


# ============================================================================
# 실습 6: ANN 인덱스 알고리즘 이해하기
# ============================================================================

def demo_index_algorithms():
    """실습 6: ANN 인덱스 알고리즘 이해하기"""
    print("\n" + "="*80)
    print("[6] 실습 6: ANN 인덱스 알고리즘 이해하기")
    print("="*80)
    print("목표: Vector DB가 빠른 검색을 가능하게 하는 알고리즘 원리 이해")
    print("핵심: 정확도와 속도 사이의 Trade-off")
    
    # ANN이 필요한 이유
    print_section_header("왜 ANN(Approximate Nearest Neighbor)이 필요한가?", "[INFO]")
    print("""
  ┌─────────────────────────────────────────────────────────┐
  │  [!] 문제: 정확한 검색(Exact Search)은 느리다           │
  │  ─────────────────────────────────────────────────────  │
  │                                                         │
  │  정확한 검색 (Brute-Force):                             │
  │  * 모든 벡터와 거리 계산 → O(N × D)                     │
  │  * N = 벡터 개수, D = 차원 수                           │
  │                                                         │
  │  예시 (1536차원):                                       │
  │  ┌──────────────┬─────────────┬───────────────────────┐ │
  │  │ 벡터 개수    │ 브루트포스  │ 실시간 서비스 가능?   │ │
  │  ├──────────────┼─────────────┼───────────────────────┤ │
  │  │ 1,000개      │ ~1ms        │ ✓ 가능               │ │
  │  │ 10,000개     │ ~10ms       │ ✓ 가능               │ │
  │  │ 100,000개    │ ~100ms      │ △ 경계선             │ │
  │  │ 1,000,000개  │ ~1초        │ ✗ 불가능             │ │
  │  │ 10,000,000개 │ ~10초       │ ✗ 완전 불가          │ │
  │  └──────────────┴─────────────┴───────────────────────┘ │
  │                                                         │
  │  [>>>] 해결책: ANN (근사 최근접 이웃)                   │
  │  * 100% 정확하지는 않지만, 훨씬 빠름                    │
  │  * 보통 95~99% 정확도로 1000배 빠른 검색 가능          │
  └─────────────────────────────────────────────────────────┘
    """)
    
    # 주요 인덱스 알고리즘
    print_section_header("주요 ANN 인덱스 알고리즘", "[ALGO]")
    
    # 1. HNSW
    print_subsection("1. HNSW (Hierarchical Navigable Small World)")
    print("""
  ┌─────────────────────────────────────────────────────────┐
  │  HNSW - ChromaDB의 기본 인덱스                          │
  │  ─────────────────────────────────────────────────────  │
  │                                                         │
  │  [원리] 계층적 그래프 구조                              │
  │                                                         │
  │     Layer 2 (상위):  ●───────────────●  (노드 적음)     │
  │                       │               │                 │
  │     Layer 1 (중간):  ●───●───●───●───●  (노드 중간)     │
  │                       │   │   │   │   │                 │
  │     Layer 0 (하위):  ●●●●●●●●●●●●●●●●●●  (모든 노드)     │
  │                                                         │
  │  [검색 과정]                                            │
  │  1. 최상위 레이어에서 시작                              │
  │  2. 가까운 이웃으로 이동하며 하위 레이어로 내려감       │
  │  3. 최하위 레이어에서 정밀 검색                         │
  │                                                         │
  │  [장점]                                                 │
  │  * 검색 속도: O(log N) - 매우 빠름                      │
  │  * 정확도: 95~99% (파라미터 조정 가능)                  │
  │  * 동적 추가/삭제 가능                                  │
  │                                                         │
  │  [단점]                                                 │
  │  * 인덱스 구축 시간 오래 걸림                           │
  │  * 메모리 사용량이 데이터보다 큼                        │
  │                                                         │
  │  [ChromaDB 설정]                                        │
  │  metadata={                                             │
  │      "hnsw:space": "cosine",                            │
  │      "hnsw:M": 16,              # 연결 수              │
  │      "hnsw:ef_construction": 100 # 구축 품질           │
  │  }                                                      │
  └─────────────────────────────────────────────────────────┘
    """)
    
    # 2. IVF
    print_subsection("2. IVF (Inverted File Index)")
    print("""
  ┌─────────────────────────────────────────────────────────┐
  │  IVF - 클러스터 기반 인덱스                             │
  │  ─────────────────────────────────────────────────────  │
  │                                                         │
  │  [원리] 벡터들을 클러스터로 그룹화                      │
  │                                                         │
  │        ┌─────┐  ┌─────┐  ┌─────┐  ┌─────┐              │
  │        │ C1  │  │ C2  │  │ C3  │  │ C4  │  ← Centroids │
  │        │●●●● │  │●●●●●│  │●●●  │  │●●●●●│  ← Vectors   │
  │        └─────┘  └─────┘  └─────┘  └─────┘              │
  │                                                         │
  │  [검색 과정]                                            │
  │  1. 쿼리와 가장 가까운 클러스터 중심 찾기               │
  │  2. 해당 클러스터 내에서만 검색                         │
  │  3. 전체 검색 대비 훨씬 적은 벡터만 비교                │
  │                                                         │
  │  [장점]                                                 │
  │  * 메모리 효율적 (HNSW보다 적음)                        │
  │  * 대용량 데이터에 적합                                 │
  │  * 구축 속도 빠름                                       │
  │                                                         │
  │  [단점]                                                 │
  │  * HNSW보다 정확도 낮을 수 있음                         │
  │  * 클러스터 경계에 있는 벡터 놓칠 수 있음               │
  │                                                         │
  │  [Faiss 설정 예시]                                      │
  │  index = faiss.IndexIVFFlat(                            │
  │      quantizer, dimension, nlist=100                    │
  │  )                                                      │
  └─────────────────────────────────────────────────────────┘
    """)
    
    # 3. PQ
    print_subsection("3. PQ (Product Quantization) - 압축 기법")
    print("""
  ┌─────────────────────────────────────────────────────────┐
  │  PQ - 벡터 압축으로 메모리 절약                         │
  │  ─────────────────────────────────────────────────────  │
  │                                                         │
  │  [원리] 고차원 벡터를 작은 조각으로 나누어 양자화       │
  │                                                         │
  │  원본 벡터 (1536차원):                                  │
  │  [0.1, 0.3, ..., 0.2, 0.5, ..., 0.4, 0.1, ...]         │
  │    └── 192차원 ──┘└── 192차원 ──┘└── 192차원 ──┘       │
  │                                                         │
  │  각 조각을 코드북의 ID로 변환:                          │
  │  [code_23,    code_156,    code_89,    ...]            │
  │                                                         │
  │  [효과]                                                 │
  │  * 1536차원 × 4바이트 = 6144바이트/벡터                │
  │  * PQ 압축 후: 8~64바이트/벡터 (100배 압축!)            │
  │                                                         │
  │  [장점]                                                 │
  │  * 메모리 사용량 대폭 감소                              │
  │  * 10억 개 벡터도 메모리에 적재 가능                    │
  │                                                         │
  │  [단점]                                                 │
  │  * 정확도 손실 (압축 손실)                              │
  │  * 보통 IVF와 결합 (IVFPQ)                              │
  │                                                         │
  │  [실무 조합] IVF + PQ = IVFPQ                           │
  │  * 대용량 + 제한된 메모리 환경에 최적                   │
  └─────────────────────────────────────────────────────────┘
    """)
    
    # 알고리즘 비교표
    print_section_header("인덱스 알고리즘 비교", "[vs]")
    print("""
  ┌─────────────────────────────────────────────────────────────────────────┐
  │  [CMP] 인덱스 알고리즘 비교표                                            │
  │  ─────────────────────────────────────────────────────────────────────  │
  │                                                                         │
  │  알고리즘   │ 검색속도 │ 정확도 │ 메모리 │ 구축속도 │ 동적추가 │ 용도   │
  │  ──────────┼─────────┼───────┼───────┼─────────┼─────────┼────────│
  │  Brute     │ O(N)    │ 100%  │ 낮음  │ 없음    │ ✓       │ 소량   │
  │  HNSW      │ O(logN) │ 높음  │ 높음  │ 느림    │ ✓       │ 범용   │
  │  IVF       │ O(N/k)  │ 중간  │ 중간  │ 빠름    │ △       │ 대용량 │
  │  IVFPQ     │ O(N/k)  │ 낮음  │ 낮음  │ 빠름    │ △       │ 초대용 │
  │  ──────────┴─────────┴───────┴───────┴─────────┴─────────┴────────│
  │                                                                         │
  │  [TIP] 선택 가이드:                                                     │
  │  * < 10만 건: Brute-Force 또는 HNSW                                     │
  │  * 10만 ~ 100만 건: HNSW (ChromaDB 기본)                                │
  │  * 100만 ~ 1000만 건: IVF 또는 HNSW                                     │
  │  * > 1000만 건: IVFPQ (압축 필수)                                       │
  │                                                                         │
  │  [!] ChromaDB는 HNSW만 지원                                             │
  │  [!] IVF, PQ가 필요하면 Faiss, Milvus 등 고려                           │
  └─────────────────────────────────────────────────────────────────────────┘
    """)
    
    # HNSW 파라미터 튜닝
    print_section_header("HNSW 파라미터 튜닝 (ChromaDB)", "[TUNE]")
    print("""
  ┌─────────────────────────────────────────────────────────┐
  │  [CODE] ChromaDB HNSW 파라미터 설정                     │
  │  ─────────────────────────────────────────────────────  │
  │                                                         │
  │  collection = client.create_collection(                 │
  │      name="tuned_collection",                           │
  │      metadata={                                         │
  │          "hnsw:space": "cosine",    # 거리 함수         │
  │          "hnsw:M": 16,              # 연결 수           │
  │          "hnsw:ef_construction": 100, # 구축 품질       │
  │          "hnsw:ef": 10,             # 검색 품질         │
  │      }                                                  │
  │  )                                                      │
  │                                                         │
  │  [파라미터 설명]                                        │
  │                                                         │
  │  1. M (연결 수, 기본값: 16)                             │
  │     * 각 노드가 가지는 이웃 연결 수                     │
  │     * ↑ 높을수록: 정확도 ↑, 메모리 ↑                   │
  │     * 권장: 12~48                                       │
  │                                                         │
  │  2. ef_construction (구축 시 탐색 폭, 기본: 100)        │
  │     * 인덱스 구축 시 탐색하는 이웃 후보 수              │
  │     * ↑ 높을수록: 인덱스 품질 ↑, 구축 시간 ↑           │
  │     * 권장: 100~500                                     │
  │                                                         │
  │  3. ef (검색 시 탐색 폭, 기본: 10)                      │
  │     * 검색 시 탐색하는 이웃 후보 수                     │
  │     * ↑ 높을수록: 정확도 ↑, 검색 속도 ↓                │
  │     * 권장: 50~200                                      │
  │                                                         │
  │  [실험 권장]                                            │
  │  * 정확도 우선: M=32, ef_construction=200, ef=100       │
  │  * 속도 우선: M=12, ef_construction=100, ef=20          │
  │  * 균형: M=16, ef_construction=100, ef=50               │
  └─────────────────────────────────────────────────────────┘
    """)
    
    # 핵심 포인트
    print_key_points([
        "- ANN: 95%+ 정확도로 1000배 빠른 검색",
        "- HNSW: 계층 그래프, ChromaDB 기본, 범용적",
        "- IVF: 클러스터 기반, 대용량, Faiss에서 사용",
        "- PQ: 벡터 압축, 메모리 100배 절약, 초대용량용",
        "- 실무: 데이터 규모에 따라 알고리즘 선택",
        "- ChromaDB: HNSW 파라미터 튜닝 가능"
    ])


# ============================================================================
# 실습 7: 대용량 데이터 처리 전략
# ============================================================================

def demo_scaling_strategies():
    """실습 7: 대용량 데이터 처리 전략"""
    print("\n" + "="*80)
    print("[7] 실습 7: 대용량 데이터 처리 전략")
    print("="*80)
    print("목표: 100만 건 이상의 벡터를 효율적으로 처리하는 방법 학습")
    print("핵심: 메모리 관리, 배치 처리, 샤딩, 필터링 최적화")
    
    # 대용량 데이터의 도전
    print_section_header("대용량 데이터의 도전", "[!]")
    print("""
  ┌─────────────────────────────────────────────────────────┐
  │  [WARN] 대용량 Vector DB 운영 시 고려사항               │
  │  ─────────────────────────────────────────────────────  │
  │                                                         │
  │  1. 메모리 사용량                                       │
  │     * 1536차원 벡터 × 4바이트 = 6KB/벡터                │
  │     * 100만 벡터 = 6GB (벡터만)                         │
  │     * HNSW 인덱스 = 추가 2~4배 메모리                   │
  │     * → 100만 벡터 HNSW ≈ 18~30GB 필요                 │
  │                                                         │
  │  2. 인덱스 구축 시간                                    │
  │     * 100만 벡터 HNSW 구축 ≈ 30분~2시간                 │
  │     * 1000만 벡터 ≈ 5~10시간                            │
  │                                                         │
  │  3. 검색 지연 시간                                      │
  │     * 로컬 SSD: 10~50ms/쿼리                            │
  │     * 네트워크 DB: 50~200ms/쿼리                        │
  │                                                         │
  │  4. 비용                                                │
  │     * 임베딩: $0.02/1M토큰 (text-embedding-3-small)     │
  │     * 100만 문서 × 500토큰 = $10 (최초 인덱싱)          │
  └─────────────────────────────────────────────────────────┘
    """)
    
    # 전략 1: 배치 처리
    print_section_header("전략 1: 배치 처리 (Batch Processing)", "[BATCH]")
    print("""
  ┌─────────────────────────────────────────────────────────┐
  │  [CODE] 대용량 임베딩 배치 처리                         │
  │  ─────────────────────────────────────────────────────  │
  │                                                         │
  │  # ❌ 나쁜 예: 개별 API 호출                            │
  │  for doc in documents:  # 100만 번!                     │
  │      embedding = get_embedding(doc)                     │
  │      collection.add(...)                                │
  │                                                         │
  │  # ✓ 좋은 예: 배치 처리                                 │
  │  BATCH_SIZE = 100  # OpenAI 권장: 최대 2048             │
  │                                                         │
  │  for i in range(0, len(documents), BATCH_SIZE):         │
  │      batch = documents[i:i+BATCH_SIZE]                  │
  │      embeddings = get_embeddings_batch(batch)           │
  │      collection.add(...)                                │
  │                                                         │
  │  [효과]                                                 │
  │  * API 호출: 100만 → 1만 (100배 감소)                   │
  │  * 처리 시간: 10시간 → 1시간                            │
  └─────────────────────────────────────────────────────────┘
    """)
    
    # 전략 2: 샤딩
    print_section_header("전략 2: 샤딩 (Sharding)", "[SHARD]")
    print("""
  ┌─────────────────────────────────────────────────────────┐
  │  [ARCH] 데이터를 여러 컬렉션/서버로 분산                │
  │  ─────────────────────────────────────────────────────  │
  │                                                         │
  │  방법 1: 카테고리 기반 샤딩                             │
  │                                                         │
  │  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐  │
  │  │ tech_docs    │  │ legal_docs   │  │ hr_docs      │  │
  │  │ 50만 건      │  │ 30만 건      │  │ 20만 건      │  │
  │  └──────────────┘  └──────────────┘  └──────────────┘  │
  │                                                         │
  │  [CODE]                                                 │
  │  def get_collection(category):                          │
  │      return client.get_collection(f"{category}_docs")   │
  │                                                         │
  │  results = get_collection("tech").query(...)            │
  │                                                         │
  │  방법 2: 시간 기반 샤딩                                 │
  │  * docs_2024_Q1, docs_2024_Q2, ...                     │
  │  * 오래된 데이터 아카이브/삭제 편리                     │
  │                                                         │
  │  [장점]                                                 │
  │  * 각 컬렉션 크기 관리 용이                             │
  │  * 병렬 검색 가능                                       │
  │                                                         │
  │  [단점]                                                 │
  │  * 전체 검색 시 여러 컬렉션 조회 필요                   │
  │  * 결과 병합 로직 필요                                  │
  └─────────────────────────────────────────────────────────┘
    """)
    
    # 전략 3: 메타데이터 필터 최적화
    print_section_header("전략 3: 메타데이터 필터 최적화", "[FILTER]")
    print("""
  ┌─────────────────────────────────────────────────────────┐
  │  [TIP] 필터링으로 검색 범위 축소                        │
  │  ─────────────────────────────────────────────────────  │
  │                                                         │
  │  # ❌ 전체 검색 후 필터링 (느림)                        │
  │  results = collection.query(                            │
  │      query_embeddings=[embedding],                      │
  │      n_results=1000                                     │
  │  )                                                      │
  │  filtered = [r for r in results if r.year == 2024]     │
  │                                                         │
  │  # ✓ 검색 시 필터 적용 (빠름)                          │
  │  results = collection.query(                            │
  │      query_embeddings=[embedding],                      │
  │      n_results=10,                                      │
  │      where={"year": 2024}  # DB 레벨 필터링             │
  │  )                                                      │
  │                                                         │
  │  [메타데이터 설계 팁]                                   │
  │  * 자주 필터링하는 필드는 반드시 메타데이터로           │
  │  * 낮은 카디널리티: category (10개) → 효율적            │
  │  * 높은 카디널리티: user_id (100만개) → 비효율적        │
  └─────────────────────────────────────────────────────────┘
    """)
    
    # 전략 4: 캐싱
    print_section_header("전략 4: 캐싱 (Caching)", "[CACHE]")
    print("""
  ┌─────────────────────────────────────────────────────────┐
  │  [ARCH] 자주 사용되는 쿼리/결과 캐싱                    │
  │  ─────────────────────────────────────────────────────  │
  │                                                         │
  │  1. 임베딩 캐싱                                         │
  │                                                         │
  │  from functools import lru_cache                        │
  │                                                         │
  │  @lru_cache(maxsize=1000)                               │
  │  def get_cached_embedding(text_hash: str):              │
  │      return get_embedding(original_text)                │
  │                                                         │
  │  # 또는 Redis 사용                                      │
  │  def get_embedding_with_redis(text: str):               │
  │      cache_key = f"emb:{hash(text)}"                    │
  │      cached = redis.get(cache_key)                      │
  │      if cached:                                         │
  │          return json.loads(cached)                      │
  │      embedding = get_embedding(text)                    │
  │      redis.setex(cache_key, 3600, json.dumps(embedding))│
  │      return embedding                                   │
  │                                                         │
  │  [효과]                                                 │
  │  * 반복 쿼리: 100ms → 1ms                               │
  │  * 임베딩 API 비용 절감                                 │
  │  * DB 부하 감소                                         │
  └─────────────────────────────────────────────────────────┘
    """)
    
    # 전략 5: 하드웨어 고려
    print_section_header("전략 5: 하드웨어 및 인프라", "[INFRA]")
    print("""
  ┌─────────────────────────────────────────────────────────┐
  │  [SPEC] 규모별 권장 사양                                │
  │  ─────────────────────────────────────────────────────  │
  │                                                         │
  │  ┌──────────────┬────────────┬────────────┬───────────┐ │
  │  │ 벡터 수      │ RAM        │ Storage    │ 구성      │ │
  │  ├──────────────┼────────────┼────────────┼───────────┤ │
  │  │ < 10만       │ 8GB        │ SSD 50GB   │ 단일 노드 │ │
  │  │ 10만 ~ 100만 │ 32GB       │ SSD 200GB  │ 단일 노드 │ │
  │  │ 100만 ~ 500만│ 64GB       │ SSD 500GB  │ 단일 노드 │ │
  │  │ 500만 ~ 1000만│ 128GB     │ SSD 1TB    │ 샤딩 권장 │ │
  │  │ > 1000만     │ 분산 클러스터 필수                   │ │
  │  └──────────────┴────────────┴────────────┴───────────┘ │
  │                                                         │
  │  [클라우드 vs 자체 호스팅]                              │
  │                                                         │
  │  클라우드 (Pinecone, Weaviate Cloud):                   │
  │  * ✓ 관리 부담 없음, 자동 스케일링                      │
  │  * ✗ 비용 높음, 데이터 외부 저장                        │
  │                                                         │
  │  자체 호스팅 (ChromaDB, Milvus):                        │
  │  * ✓ 비용 통제, 데이터 내부 보관                        │
  │  * ✗ 운영 부담, 스케일링 직접 구현                      │
  │                                                         │
  │  [TIP] PoC는 클라우드, 프로덕션은 규모에 따라 선택      │
  └─────────────────────────────────────────────────────────┘
    """)
    
    # 체크리스트
    print_section_header("대용량 처리 체크리스트", "[CHECK]")
    print("""
  ┌─────────────────────────────────────────────────────────┐
  │  [✓] 대용량 Vector DB 운영 체크리스트                   │
  │  ─────────────────────────────────────────────────────  │
  │                                                         │
  │  □ 데이터 규모 파악                                     │
  │    - 현재 문서 수: _______                              │
  │    - 1년 후 예상: _______건                             │
  │                                                         │
  │  □ 메모리 계산                                          │
  │    - 벡터 메모리: 문서수 × 6KB                          │
  │    - 인덱스 메모리: 벡터 메모리 × 3                     │
  │    - 서버 RAM >= 인덱스 메모리 × 1.5                    │
  │                                                         │
  │  □ 배치 처리 구현                                       │
  │    - 임베딩 배치: 100~500                               │
  │    - DB 삽입 배치: 1000~5000                            │
  │                                                         │
  │  □ 샤딩 전략                                            │
  │    - 샤딩 기준: 카테고리 / 시간 / 해시                  │
  │                                                         │
  │  □ 캐싱 전략                                            │
  │    - 임베딩 캐시: LRU / Redis                           │
  │                                                         │
  │  □ 모니터링                                             │
  │    - 검색 지연 시간                                     │
  │    - 메모리 사용량                                      │
  │    - API 비용                                           │
  └─────────────────────────────────────────────────────────┘
    """)
    
    # 핵심 포인트
    print_key_points([
        "- 배치 처리: API 호출 100배 감소",
        "- 샤딩: 카테고리/시간 기준 데이터 분산",
        "- 메타데이터 필터: DB 레벨 필터링으로 효율 향상",
        "- 캐싱: 반복 쿼리 100배 빠름",
        "- 하드웨어: 100만 벡터 ≈ 64GB RAM (HNSW)",
        "- 실무: 작게 시작, 점진적 확장"
    ])


# ============================================================================
# 메인 실행
# ============================================================================

def main():
    """챕터 3 실행"""
    print("\n" + "="*80)
    print("[Chapter 3] 심화 이론 - 확장성과 최적화")
    print("="*80)
    
    print("\n학습 목표:")
    print("  • Vector DB가 빠른 이유 (ANN 알고리즘)")
    print("  • HNSW, IVF, PQ 등 인덱스 알고리즘 비교")
    print("  • 100만 건 이상 처리 시 고려사항")
    print("  • 실무 스케일링 전략")
    
    print("\n[INFO] 이 챕터는 이론 중심이므로 API 키 없이도 학습 가능합니다.")
    
    try:
        # 실습 6: ANN 인덱스 알고리즘
        demo_index_algorithms()
        
        # 실습 7: 대용량 처리 전략
        demo_scaling_strategies()
        
        # 완료 메시지
        print("\n" + "="*80)
        print("[OK] Chapter 3 완료!")
        print("="*80)
        
        print("\n[요약]")
        print("  • ANN: 95%+ 정확도로 1000배 빠름")
        print("  • HNSW: ChromaDB 기본, 범용적")
        print("  • 배치/샤딩/캐싱: 대용량 처리 핵심 전략")
        print("  • 메모리 계산: 100만 벡터 ≈ 18~30GB")
        
        print("\n[전체 Lab02 완료!]")
        print("  ✓ Chapter 1: Vector DB 기초")
        print("  ✓ Chapter 2: 실전 활용 (메타데이터, DocumentManager)")
        print("  ✓ Chapter 3: 심화 이론 (ANN, 스케일링)")
        
        print("\n[다음 단계]")
        print("  • lab03/rag_basic.py: RAG 시스템 구축")
        print("  • Vector DB + LLM = 실전 AI 애플리케이션")
        
    except Exception as e:
        print(f"\n[X] 오류 발생: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()

